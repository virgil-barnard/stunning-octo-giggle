{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36d36abc-93c2-4fd3-baed-81a4b6b6a4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -U langchain_community tiktoken langchain-openai langchainhub chromadb langchain langgraph faiss-cpu\n",
    "key = \"yours\"\n",
    "import os\n",
    "import json\n",
    "os.environ[\"OPENAI_API_KEY\"] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9b30d6b-15b8-4752-bd24-15d43ad87622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as Soup\n",
    "from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader\n",
    "\n",
    "# LCEL docs\n",
    "url = \"https://python.langchain.com/docs/expression_language/\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url, max_depth=20, extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# LCEL w/ PydanticOutputParser (outside the primary LCEL docs)\n",
    "url = \"https://python.langchain.com/docs/modules/model_io/output_parsers/quick_start\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url, max_depth=1, extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "docs_pydantic = loader.load()\n",
    "\n",
    "# LCEL w/ Self Query (outside the primary LCEL docs)\n",
    "url = \"https://python.langchain.com/docs/modules/data_connection/retrievers/self_query/\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url, max_depth=1, extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "docs_sq = loader.load()\n",
    "\n",
    "# Add\n",
    "docs.extend([*docs_pydantic, *docs_sq])\n",
    "\n",
    "# Sort the list based on the URLs in 'metadata' -> 'source'\n",
    "d_sorted = sorted(docs, key=lambda x: x.metadata[\"source\"])\n",
    "d_reversed = list(reversed(d_sorted))\n",
    "\n",
    "# Concatenate the 'page_content' of each sorted dictionary\n",
    "concatenated_content = \"\\n\\n\\n --- \\n\\n\\n\".join(\n",
    "    [doc.page_content for doc in d_reversed]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fff43cf7-aca0-4945-937f-678643cf46bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, TypedDict\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        keys: A dictionary where each key is a string.\n",
    "    \"\"\"\n",
    "\n",
    "    keys: Dict[str, any]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5345527-3ca6-49e9-b657-c8d7bf95617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.output_parsers.openai_tools import PydanticToolsParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "def generate(state: GraphState):\n",
    "    \"\"\"\n",
    "    Generate a code solution based on LCEL docs and the input question\n",
    "    with optional feedback from code execution tests\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "\n",
    "    ## State\n",
    "    state_dict = state[\"keys\"]\n",
    "    question = state_dict[\"question\"]\n",
    "    iter = state_dict[\"iterations\"]\n",
    "\n",
    "    ## Data model\n",
    "    class code(BaseModel):\n",
    "        \"\"\"Code output\"\"\"\n",
    "\n",
    "        prefix: str = Field(description=\"Description of the problem and approach\")\n",
    "        imports: str = Field(description=\"Code block import statements\")\n",
    "        code: str = Field(description=\"Code block not including import statements\")\n",
    "\n",
    "    ## LLM\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4-0125-preview\", streaming=True)\n",
    "\n",
    "    # Tool\n",
    "    code_tool_oai = convert_to_openai_tool(code)\n",
    "\n",
    "    # LLM with tool and enforce invocation\n",
    "    llm_with_tool = model.bind(\n",
    "        tools=[code_tool_oai],\n",
    "        tool_choice={\"type\": \"function\", \"function\": {\"name\": \"code\"}},\n",
    "    )\n",
    "\n",
    "    # Parser\n",
    "    parser_tool = PydanticToolsParser(tools=[code])\n",
    "\n",
    "    ## Prompt\n",
    "    template = \"\"\"You are a coding assistant with expertise in LCEL, LangChain expression language. \\n \n",
    "        Here is a full set of LCEL documentation: \n",
    "        \\n ------- \\n\n",
    "        {context} \n",
    "        \\n ------- \\n\n",
    "        Answer the user question based on the above provided documentation. \\n\n",
    "        Ensure any code you provide can be executed with all required imports and variables defined. \\n\n",
    "        Structure your answer with a description of the code solution. \\n\n",
    "        Then list the imports. And finally list the functioning code block. \\n\n",
    "        Here is the user question: \\n --- --- --- \\n {question}\"\"\"\n",
    "\n",
    "    ## Generation\n",
    "    if \"error\" in state_dict:\n",
    "        print(\"---RE-GENERATE SOLUTION w/ ERROR FEEDBACK---\")\n",
    "\n",
    "        error = state_dict[\"error\"]\n",
    "        code_solution = state_dict[\"generation\"]\n",
    "\n",
    "        # Udpate prompt\n",
    "        addendum = \"\"\"  \\n --- --- --- \\n You previously tried to solve this problem. \\n Here is your solution:  \n",
    "                    \\n --- --- --- \\n {generation}  \\n --- --- --- \\n  Here is the resulting error from code \n",
    "                    execution:  \\n --- --- --- \\n {error}  \\n --- --- --- \\n Please re-try to answer this. \n",
    "                    Structure your answer with a description of the code solution. \\n Then list the imports. \n",
    "                    And finally list the functioning code block. Structure your answer with a description of \n",
    "                    the code solution. \\n Then list the imports. And finally list the functioning code block. \n",
    "                    \\n Here is the user question: \\n --- --- --- \\n {question}\"\"\"\n",
    "        template = template + addendum\n",
    "\n",
    "        # Prompt\n",
    "        prompt = PromptTemplate(\n",
    "            template=template,\n",
    "            input_variables=[\"context\", \"question\", \"generation\", \"error\"],\n",
    "        )\n",
    "\n",
    "        # Chain\n",
    "        chain = (\n",
    "            {\n",
    "                \"context\": lambda _: concatenated_content,\n",
    "                \"question\": itemgetter(\"question\"),\n",
    "                \"generation\": itemgetter(\"generation\"),\n",
    "                \"error\": itemgetter(\"error\"),\n",
    "            }\n",
    "            | prompt\n",
    "            | llm_with_tool\n",
    "            | parser_tool\n",
    "        )\n",
    "\n",
    "        code_solution = chain.invoke(\n",
    "            {\"question\": question, \"generation\": str(code_solution[0]), \"error\": error}\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        print(\"---GENERATE SOLUTION---\")\n",
    "\n",
    "        # Prompt\n",
    "        prompt = PromptTemplate(\n",
    "            template=template,\n",
    "            input_variables=[\"context\", \"question\"],\n",
    "        )\n",
    "\n",
    "        # Chain\n",
    "        chain = (\n",
    "            {\n",
    "                \"context\": lambda _: concatenated_content,\n",
    "                \"question\": itemgetter(\"question\"),\n",
    "            }\n",
    "            | prompt\n",
    "            | llm_with_tool\n",
    "            | parser_tool\n",
    "        )\n",
    "\n",
    "        code_solution = chain.invoke({\"question\": question})\n",
    "\n",
    "    iter = iter + 1\n",
    "    return {\n",
    "        \"keys\": {\"generation\": code_solution, \"question\": question, \"iterations\": iter}\n",
    "    }\n",
    "\n",
    "\n",
    "def check_code_imports(state: GraphState):\n",
    "    \"\"\"\n",
    "    Check imports\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, error\n",
    "    \"\"\"\n",
    "\n",
    "    ## State\n",
    "    print(\"---CHECKING CODE IMPORTS---\")\n",
    "    state_dict = state[\"keys\"]\n",
    "    question = state_dict[\"question\"]\n",
    "    code_solution = state_dict[\"generation\"]\n",
    "    imports = code_solution[0].imports\n",
    "    iter = state_dict[\"iterations\"]\n",
    "\n",
    "    try:\n",
    "        # Attempt to execute the imports\n",
    "        exec(imports)\n",
    "    except Exception as e:\n",
    "        print(\"---CODE IMPORT CHECK: FAILED---\")\n",
    "        # Catch any error during execution (e.g., ImportError, SyntaxError)\n",
    "        error = f\"Execution error: {e}\"\n",
    "        if \"error\" in state_dict:\n",
    "            error_prev_runs = state_dict[\"error\"]\n",
    "            error = error_prev_runs + \"\\n --- Most recent run error --- \\n\" + error\n",
    "    else:\n",
    "        print(\"---CODE IMPORT CHECK: SUCCESS---\")\n",
    "        # No errors occurred\n",
    "        error = \"None\"\n",
    "\n",
    "    return {\n",
    "        \"keys\": {\n",
    "            \"generation\": code_solution,\n",
    "            \"question\": question,\n",
    "            \"error\": error,\n",
    "            \"iterations\": iter,\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def check_code_execution(state: GraphState):\n",
    "    \"\"\"\n",
    "    Check code block execution\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, error\n",
    "    \"\"\"\n",
    "\n",
    "    ## State\n",
    "    print(\"---CHECKING CODE EXECUTION---\")\n",
    "    state_dict = state[\"keys\"]\n",
    "    question = state_dict[\"question\"]\n",
    "    code_solution = state_dict[\"generation\"]\n",
    "    prefix = code_solution[0].prefix\n",
    "    imports = code_solution[0].imports\n",
    "    code = code_solution[0].code\n",
    "    code_block = imports + \"\\n\" + code\n",
    "    iter = state_dict[\"iterations\"]\n",
    "\n",
    "    try:\n",
    "        # Attempt to execute the code block\n",
    "        exec(code_block)\n",
    "    except Exception as e:\n",
    "        print(\"---CODE BLOCK CHECK: FAILED---\")\n",
    "        # Catch any error during execution (e.g., ImportError, SyntaxError)\n",
    "        error = f\"Execution error: {e}\"\n",
    "        if \"error\" in state_dict:\n",
    "            error_prev_runs = state_dict[\"error\"]\n",
    "            error = error_prev_runs + \"\\n --- Most recent run error --- \\n\" + error\n",
    "    else:\n",
    "        print(\"---CODE BLOCK CHECK: SUCCESS---\")\n",
    "        # No errors occurred\n",
    "        error = \"None\"\n",
    "\n",
    "    return {\n",
    "        \"keys\": {\n",
    "            \"generation\": code_solution,\n",
    "            \"question\": question,\n",
    "            \"error\": error,\n",
    "            \"prefix\": prefix,\n",
    "            \"imports\": imports,\n",
    "            \"iterations\": iter,\n",
    "            \"code\": code,\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "### Edges\n",
    "\n",
    "\n",
    "def decide_to_check_code_exec(state: GraphState):\n",
    "    \"\"\"\n",
    "    Determines whether to test code execution, or re-try answer generation.\n",
    "\n",
    "    Args:\n",
    "       state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---DECIDE TO TEST CODE EXECUTION---\")\n",
    "    state_dict = state[\"keys\"]\n",
    "    error = state_dict[\"error\"]\n",
    "\n",
    "    if error == \"None\":\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\"---DECISION: TEST CODE EXECUTION---\")\n",
    "        return \"check_code_execution\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: RE-TRY SOLUTION---\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "def decide_to_finish(state: GraphState):\n",
    "    \"\"\"\n",
    "    Determines whether to finish (re-try code 3 times.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---DECIDE TO TEST CODE EXECUTION---\")\n",
    "    state_dict = state[\"keys\"]\n",
    "    error = state_dict[\"error\"]\n",
    "    iter = state_dict[\"iterations\"]\n",
    "\n",
    "    if error == \"None\" or iter == 3:\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\"---DECISION: TEST CODE EXECUTION---\")\n",
    "        return \"end\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: RE-TRY SOLUTION---\")\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "260d595f-bd0e-4d9e-9c10-8b8321d7d0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"generate\", generate)  # generation solution\n",
    "workflow.add_node(\"check_code_imports\", check_code_imports)  # check imports\n",
    "workflow.add_node(\"check_code_execution\", check_code_execution)  # check execution\n",
    "\n",
    "# Build graph\n",
    "workflow.set_entry_point(\"generate\")\n",
    "workflow.add_edge(\"generate\", \"check_code_imports\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_code_imports\",\n",
    "    decide_to_check_code_exec,\n",
    "    {\n",
    "        \"check_code_execution\": \"check_code_execution\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_code_execution\",\n",
    "    decide_to_finish,\n",
    "    {\n",
    "        \"end\": END,\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Compile\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "089be316-ea2e-48de-808a-8ef35bd52078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "## Data model\n",
    "class code(BaseModel):\n",
    "    \"\"\"Code output\"\"\"\n",
    "\n",
    "    prefix: str = Field(description=\"Description of the problem and approach\")\n",
    "    imports: str = Field(description=\"Code block import statements\")\n",
    "    code: str = Field(description=\"Code block not including import statements\")\n",
    "\n",
    "\n",
    "## LLM\n",
    "model = ChatOpenAI(temperature=0, model=\"gpt-4-0125-preview\", streaming=True)\n",
    "\n",
    "# Tool\n",
    "code_tool_oai = convert_to_openai_tool(code)\n",
    "\n",
    "# LLM with tool and enforce invocation\n",
    "llm_with_tool = model.bind(\n",
    "    tools=[convert_to_openai_tool(code_tool_oai)],\n",
    "    tool_choice={\"type\": \"function\", \"function\": {\"name\": \"code\"}},\n",
    ")\n",
    "\n",
    "# Parser\n",
    "parser_tool = PydanticToolsParser(tools=[code])\n",
    "\n",
    "# Create a prompt template with format instructions and the query\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a coding assistant with expertise in LCEL, LangChain expression language. \\n \n",
    "        Here is a full set of LCEL documentation: \n",
    "        \\n ------- \\n\n",
    "        {context} \n",
    "        \\n ------- \\n\n",
    "        Answer the user question based on the above provided documentation. \\n\n",
    "        Ensure any code you provide can be executed with all required imports and variables defined. \\n\n",
    "        Structure your answer with a description of the code solution. \\n\n",
    "        Then list the imports. And finally list the functioning code block. \\n\n",
    "        Here is the user question: \\n --- --- --- \\n {question}\"\"\",\n",
    "    input_variables=[\"question\", \"context\"],\n",
    ")\n",
    "\n",
    "\n",
    "def parse_answer_to_dict(x):\n",
    "    return x[0].dict()\n",
    "\n",
    "\n",
    "chain_base_case = (\n",
    "    {\n",
    "        \"context\": lambda _: concatenated_content,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tool\n",
    "    | parser_tool\n",
    "    | RunnableLambda(parse_answer_to_dict)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72919396-07c8-408a-bc38-42ca24a1758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = chain_base_case.invoke(\"I'm working with multi-agent teams to complete tasks with langchain. In that paradigm the agents are given tools they can interact with on the host system that allow them to complete the tasks by executing the tools on the host system. In dynamic problem solving it is difficult to know what tools they should have a-priori. I want to develop a set of tools and new paradigm that allows them to create tools as needed and update a tool bank that they can use. This probably requires some technical work on the backend for updating a tool bank, retrieving tool descriptions for them on request to include the new tools created, and interacting with the agents requests to use the tools whenever they request them and send their inputs. I'm also thinking that I should use a RAG system to allow them to search for existing tools in the database by semantic similarity based on the tool description field and their description of the type of tool they want. If the tool they want doesn't exist then they send a request to a tool creator agent team that builds the tool according to the requirements requested, and they build test cases and save the tool out into the tool bank whenever it's completed and let the requester know they can access the tool. The complicated part will be how can I allow the other agents have access to these tools as they get dynamically created. I'm thinking they might have to have a tool retriever tool that loads up the new tool on request and runs it. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1de9837d-7956-44ac-8cc3-b076500c130f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': '# Initialize the tool bank\\n'\n",
      "         'def initialize_system():\\n'\n",
      "         '    create_tool_bank()\\n'\n",
      "         '    for tool in example_tools:\\n'\n",
      "         \"        add_tool(tool['name'], tool['description'], \"\n",
      "         \"tool['command'])\\n\"\n",
      "         '\\n'\n",
      "         '# Example usage\\n'\n",
      "         'initialize_system()\\n'\n",
      "         '\\n'\n",
      "         '# Search for a tool based on a description\\n'\n",
      "         \"searched_tool = search_tools('generates reports from data')\\n\"\n",
      "         \"print(f'Searched tool: {searched_tool}')\\n\"\n",
      "         '\\n'\n",
      "         '# Execute the searched tool\\n'\n",
      "         \"execute_tool(searched_tool['command'])\\n\",\n",
      " 'imports': 'from typing import List, Dict\\n'\n",
      "            'import sqlite3\\n'\n",
      "            'import subprocess\\n'\n",
      "            'import json\\n'\n",
      "            'from sklearn.feature_extraction.text import TfidfVectorizer\\n'\n",
      "            'from sklearn.metrics.pairwise import cosine_similarity\\n'\n",
      "            '\\n'\n",
      "            '# Assuming a simple SQLite database for the tool bank\\n'\n",
      "            \"db_connection = sqlite3.connect('tool_bank.db')\\n\"\n",
      "            '\\n'\n",
      "            'def create_tool_bank():\\n'\n",
      "            '    # Function to initialize the tool bank database\\n'\n",
      "            '    cursor = db_connection.cursor()\\n'\n",
      "            \"    cursor.execute('''CREATE TABLE IF NOT EXISTS tools (\\n\"\n",
      "            '        id INTEGER PRIMARY KEY,\\n'\n",
      "            '        name TEXT NOT NULL,\\n'\n",
      "            '        description TEXT NOT NULL,\\n'\n",
      "            '        command TEXT NOT NULL\\n'\n",
      "            \"    )''')\\n\"\n",
      "            '    db_connection.commit()\\n'\n",
      "            '\\n'\n",
      "            '# Example tool descriptions\\n'\n",
      "            'example_tools = [\\n'\n",
      "            \"    {'name': 'Calculator', 'description': 'Performs basic \"\n",
      "            \"arithmetic operations', 'command': 'python calculator.py'},\\n\"\n",
      "            \"    {'name': 'DataAnalyzer', 'description': 'Analyzes data and \"\n",
      "            \"generates reports', 'command': 'python data_analyzer.py'}\\n\"\n",
      "            ']\\n'\n",
      "            '\\n'\n",
      "            '# Function to add tools to the tool bank\\n'\n",
      "            'def add_tool(name: str, description: str, command: str):\\n'\n",
      "            '    cursor = db_connection.cursor()\\n'\n",
      "            \"    cursor.execute('INSERT INTO tools (name, description, \"\n",
      "            \"command) VALUES (?, ?, ?)', (name, description, command))\\n\"\n",
      "            '    db_connection.commit()\\n'\n",
      "            '\\n'\n",
      "            '# Function to search for tools based on description similarity\\n'\n",
      "            'def search_tools(description: str) -> List[Dict]:\\n'\n",
      "            '    cursor = db_connection.cursor()\\n'\n",
      "            \"    cursor.execute('SELECT name, description, command FROM \"\n",
      "            \"tools')\\n\"\n",
      "            '    tools = cursor.fetchall()\\n'\n",
      "            '    tool_descriptions = [tool[1] for tool in tools]\\n'\n",
      "            '    vectorizer = TfidfVectorizer().fit(tool_descriptions)\\n'\n",
      "            '    query_vec = vectorizer.transform([description])\\n'\n",
      "            '    similarity = cosine_similarity(query_vec, '\n",
      "            'vectorizer.transform(tool_descriptions))\\n'\n",
      "            '    most_similar_index = similarity.argmax()\\n'\n",
      "            \"    return {'name': tools[most_similar_index][0], 'command': \"\n",
      "            'tools[most_similar_index][2]}\\n'\n",
      "            '\\n'\n",
      "            '# Function to execute a tool command\\n'\n",
      "            'def execute_tool(command: str):\\n'\n",
      "            '    process = subprocess.Popen(command, shell=True, '\n",
      "            'stdout=subprocess.PIPE)\\n'\n",
      "            '    output, error = process.communicate()\\n'\n",
      "            '    if error:\\n'\n",
      "            \"        print(f'Error executing tool: {error}')\\n\"\n",
      "            '    else:\\n'\n",
      "            \"        print(f'Tool output: {output.decode()}')\",\n",
      " 'prefix': 'To implement a dynamic tool creation and retrieval system for '\n",
      "           \"multi-agent teams using LangChain, you'll need to design a system \"\n",
      "           'that allows agents to: \\n'\n",
      "           '\\n'\n",
      "           '1. Request new tools based on their task requirements. \\n'\n",
      "           '2. Search for existing tools in a tool bank using semantic '\n",
      "           'similarity. \\n'\n",
      "           '3. Notify and make newly created tools available to all agents. \\n'\n",
      "           '\\n'\n",
      "           'This system involves several components, including a tool bank for '\n",
      "           'storing and retrieving tools, a tool creator agent for developing '\n",
      "           'new tools based on requests, and a tool retriever for dynamically '\n",
      "           'loading and executing tools. \\n'\n",
      "           '\\n'\n",
      "           \"Here's a high-level approach to building this system: \\n\"\n",
      "           '\\n'\n",
      "           '1. **Tool Bank**: A database or repository that stores tools and '\n",
      "           'their descriptions. This can be implemented using a simple '\n",
      "           'database system where each tool is associated with metadata '\n",
      "           'describing its purpose and usage. \\n'\n",
      "           '\\n'\n",
      "           '2. **Tool Creator Agent**: An agent responsible for creating new '\n",
      "           'tools based on requests from other agents. This agent receives '\n",
      "           'tool requests, develops the tool, tests it, and then adds it to '\n",
      "           'the tool bank. \\n'\n",
      "           '\\n'\n",
      "           '3. **Tool Retriever**: An agent or function that allows other '\n",
      "           'agents to search for and retrieve tools from the tool bank. This '\n",
      "           'can use a Retrieval-Augmented Generation (RAG) system to search '\n",
      "           'for tools based on semantic similarity. \\n'\n",
      "           '\\n'\n",
      "           '4. **Dynamic Tool Loading**: Mechanism to dynamically load and '\n",
      "           'execute tools as they are requested by agents. This could involve '\n",
      "           'a runtime environment where tools can be executed in isolation for '\n",
      "           'security. \\n'\n",
      "           '\\n'\n",
      "           '5. **Notification System**: A system to notify agents when new '\n",
      "           'tools are available or when their tool requests have been '\n",
      "           'fulfilled. \\n'\n",
      "           '\\n'\n",
      "           \"Here's an example implementation outline in Python, focusing on \"\n",
      "           'the tool retrieval and dynamic execution part:'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee4568d9-dce8-483c-a18c-63a325b1ab74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "multiply(a: int, b: int) -> int - Multiply two numbers.\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8bcee3af-b296-4cbc-9ee9-de7f9a494ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import sqlite3\n",
    "import subprocess\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Assuming a simple SQLite database for the tool bank\n",
    "db_connection = sqlite3.connect('tool_bank.db')\n",
    "\n",
    "def create_tool_bank():\n",
    "    # Function to initialize the tool bank database\n",
    "    cursor = db_connection.cursor()\n",
    "    cursor.execute('''CREATE TABLE IF NOT EXISTS tools (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        name TEXT NOT NULL,\n",
    "        description TEXT NOT NULL,\n",
    "        args TEXT NOT NULL\n",
    "    )''')\n",
    "    db_connection.commit()\n",
    "\n",
    "# Example tool descriptions\n",
    "example_tools = [\n",
    "    {'name': multiply.name, 'description': multiply.description, \n",
    "     'args': multiply.args, 'function': multiply}\n",
    "]\n",
    "\n",
    "# Function to add tools to the tool bank\n",
    "# def add_tool(name: str, description: str, args: str):\n",
    "#     cursor = db_connection.cursor()\n",
    "#     cursor.execute('INSERT INTO tools (name, description, args) VALUES (?, ?, ?)', (name, description, str(args)))\n",
    "#     db_connection.commit()\n",
    "# Function to add tools to the tool bank\n",
    "def add_tool(name: str, description: str, args: str, function):\n",
    "    cursor = db_connection.cursor()\n",
    "    cursor.execute('INSERT INTO tools (name, description, args) VALUES (?, ?, ?)', (name, description, str(args)))\n",
    "    db_connection.commit()\n",
    "    # Dynamically declare the tool function in the runtime global namespace\n",
    "    globals()[name] = function\n",
    "    \n",
    "# Function to search for tools based on description similarity\n",
    "def search_tools(description: str) -> List[Dict]:\n",
    "    cursor = db_connection.cursor()\n",
    "    cursor.execute('SELECT name, description, args FROM tools')\n",
    "    tools = cursor.fetchall()\n",
    "    tool_descriptions = [tool[1] for tool in tools]\n",
    "    vectorizer = TfidfVectorizer().fit(tool_descriptions)\n",
    "    query_vec = vectorizer.transform([description])\n",
    "    similarity = cosine_similarity(query_vec, vectorizer.transform(tool_descriptions))\n",
    "    most_similar_index = similarity.argmax()\n",
    "    return {'name': tools[most_similar_index][0], 'args': tools[most_similar_index][2]}\n",
    "\n",
    "# Function to execute a tool command\n",
    "# def execute_tool(command: str):\n",
    "#     process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)\n",
    "#     output, error = process.communicate()\n",
    "#     if error:\n",
    "#         print(f'Error executing tool: {error}')\n",
    "#     else:\n",
    "#         print(f'Tool output: {output.decode()}')\n",
    "# Function to execute a tool command\n",
    "# def execute_tool(tool_name: str, args: str):\n",
    "#     cursor = db_connection.cursor()\n",
    "#     cursor.execute('SELECT args FROM tools WHERE name=?', (tool_name,))\n",
    "#     tool_args = cursor.fetchone()\n",
    "#     if tool_args:\n",
    "#         # Construct the command with tool name and arguments\n",
    "#         command = f\"{tool_name} {args}\"\n",
    "#         process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)\n",
    "#         output, error = process.communicate()\n",
    "#         if error:\n",
    "#             print(f'Error executing tool: {error}')\n",
    "#         else:\n",
    "#             print(f'Tool output: {output.decode()}')\n",
    "#     else:\n",
    "#         print(\"Tool not found in the tool bank.\")\n",
    "# Function to execute a tool command\n",
    "# def execute_tool(tool_name: str, tool_args: str):\n",
    "#     cursor = db_connection.cursor()\n",
    "#     cursor.execute('SELECT args FROM tools WHERE name=?', (tool_name,))\n",
    "#     stored_tool_args = cursor.fetchone()\n",
    "#     if stored_tool_args:\n",
    "#         # Construct the command with tool name and arguments\n",
    "#         command = f\"{tool_name} {tool_args}\"\n",
    "#         # Execute the tool command\n",
    "#         process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)\n",
    "#         output, error = process.communicate()\n",
    "#         if error:\n",
    "#             print(f'Error executing tool: {error}')\n",
    "#         else:\n",
    "#             print(f'Tool output: {output.decode()}')\n",
    "#     else:\n",
    "#         print(\"Tool not found in the tool bank.\")\n",
    "# Function to execute a tool command\n",
    "def execute_tool(tool_name: str, tool_args: str):\n",
    "    try:\n",
    "        # Dynamically retrieve the function by its name\n",
    "        tool_function = globals()[tool_name]\n",
    "        # Execute the tool function with provided arguments\n",
    "        result = tool_function(tool_args)\n",
    "        print(f'Tool output: {result}')\n",
    "    except KeyError:\n",
    "        print(\"Tool not found in the tool bank.\")\n",
    "    except Exception as e:\n",
    "        print(f'Error executing tool: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "53bfb87c-a26b-48ef-8075-904dac5efbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searched tool: {'name': 'multiply', 'args': \"{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\"}\n",
      "Tool output: 12\n"
     ]
    }
   ],
   "source": [
    "# Initialize the tool bank\n",
    "def initialize_system():\n",
    "    create_tool_bank()\n",
    "    for tool in example_tools:\n",
    "        add_tool(tool['name'], tool['description'], tool['args'], tool['function'])\n",
    "\n",
    "# Example usage\\n'\n",
    "initialize_system()\n",
    "\n",
    "# Search for a tool based on a description\\n'\n",
    "searched_tool = search_tools('multiply two numbers')\n",
    "print(f'Searched tool: {searched_tool}')\n",
    "\n",
    "# Execute the searched tool\n",
    "execute_tool(searched_tool['name'], {'a': 3, 'b': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b4ef1400-4e6c-4701-8a8a-286ed145bd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multiply'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searched_tool['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7287a1-658c-46dc-b5b1-44a8281e089c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c146d01-a548-4cd1-b1ab-466d13a1c081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e1a923-47d0-42b9-a891-96c39d469973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43afa6ef-755f-4a42-85bf-3d2db2220019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool name:  multiply\n",
      "Tool description:  multiply(a: int, b: int) -> int - Multiply two numbers.\n",
      "Tool argument schema:  {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n",
      "Searched tool: {'name': 'multiply', 'args': \"{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\"}\n",
      "Tool output: 12\n",
      "Searched tool: {'name': 'concat', 'args': \"{'a': {'title': 'A', 'type': 'string'}, 'b': {'title': 'B', 'type': 'string'}}\"}\n",
      "Tool output: helloworld\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict\n",
    "import sqlite3\n",
    "import subprocess\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Assuming a simple SQLite database for the tool bank\n",
    "db_connection = sqlite3.connect('tool_bank.db')\n",
    "\n",
    "def create_tool_bank():\n",
    "    # Function to initialize the tool bank database\n",
    "    cursor = db_connection.cursor()\n",
    "    cursor.execute('''CREATE TABLE IF NOT EXISTS tools (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        name TEXT NOT NULL,\n",
    "        description TEXT NOT NULL,\n",
    "        args TEXT NOT NULL\n",
    "    )''')\n",
    "    db_connection.commit()\n",
    "\n",
    "# Function to add tools to the tool bank\n",
    "def add_tool(name: str, description: str, args: str, function):\n",
    "    cursor = db_connection.cursor()\n",
    "    cursor.execute('INSERT INTO tools (name, description, args) VALUES (?, ?, ?)', (name, description, str(args)))\n",
    "    db_connection.commit()\n",
    "    # Dynamically declare the tool function in the runtime global namespace\n",
    "    globals()[name] = function\n",
    "    \n",
    "# Function to search for tools based on description similarity\n",
    "def search_tools(description: str) -> List[Dict]:\n",
    "    cursor = db_connection.cursor()\n",
    "    cursor.execute('SELECT name, description, args FROM tools')\n",
    "    tools = cursor.fetchall()\n",
    "    tool_descriptions = [tool[1] for tool in tools]\n",
    "    vectorizer = TfidfVectorizer().fit(tool_descriptions)\n",
    "    query_vec = vectorizer.transform([description])\n",
    "    similarity = cosine_similarity(query_vec, vectorizer.transform(tool_descriptions))\n",
    "    most_similar_index = similarity.argmax()\n",
    "    return {'name': tools[most_similar_index][0], 'args': tools[most_similar_index][2]}\n",
    "\n",
    "# Function to execute a tool command\n",
    "def execute_tool(tool_name: str, tool_args: str):\n",
    "    try:\n",
    "        # Dynamically retrieve the function by its name\n",
    "        tool_function = globals()[tool_name]\n",
    "        # Execute the tool function with provided arguments\n",
    "        result = tool_function(tool_args)\n",
    "        print(f'Tool output: {result}')\n",
    "    except KeyError:\n",
    "        print(\"Tool not found in the tool bank.\")\n",
    "    except Exception as e:\n",
    "        print(f'Error executing tool: {e}')\n",
    "\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def concat(a: str, b: str) -> str:\n",
    "    \"\"\"Concatenate two strings.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "print(\"Tool name: \", multiply.name)\n",
    "print(\"Tool description: \", multiply.description)\n",
    "print(\"Tool argument schema: \", multiply.args)\n",
    "'''\n",
    "multiply\n",
    "multiply(a: int, b: int) -> int - Multiply two numbers.\n",
    "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n",
    "'''\n",
    "\n",
    "# Example tool descriptions\n",
    "example_tools = [\n",
    "    {'name': multiply.name, 'description': multiply.description, \n",
    "     'args': multiply.args, 'function': multiply},\n",
    "    {'name': concat.name, 'description': concat.description, \n",
    "     'args': concat.args, 'function': concat}\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "# Initialize the tool bank\n",
    "def initialize_system():\n",
    "    create_tool_bank()\n",
    "    for tool in example_tools:\n",
    "        add_tool(tool['name'], tool['description'], tool['args'], tool['function'])\n",
    "\n",
    "# Example usage\\n'\n",
    "initialize_system()\n",
    "\n",
    "tool_search_query1 = 'I need a tool that allows me to take the product of two numbers'\n",
    "\n",
    "# Search for a tool based on a description\n",
    "searched_tool = search_tools(tool_search_query1)\n",
    "print(f'Searched tool: {searched_tool}')\n",
    "\n",
    "# Execute the searched tool\n",
    "execute_tool(searched_tool['name'], {'a': 3, 'b': 4})\n",
    "\n",
    "tool_search_query2 = 'I need a tool that allows me to concatenate two strings'\n",
    "\n",
    "# Search for a tool based on a description\n",
    "searched_tool = search_tools(tool_search_query2)\n",
    "print(f'Searched tool: {searched_tool}')\n",
    "\n",
    "# Execute the searched tool\n",
    "execute_tool(searched_tool['name'], {'a': 'hello', 'b': 'world'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9dca5eb-4143-419c-8d5a-f7ae87dcef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool:\n",
    "    def __init__(self, name: str, description: str, args: dict, function):\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.args = args\n",
    "        self.function = function\n",
    "\n",
    "    def validate_args(self, **kwargs):\n",
    "        # Implement validation logic based on self.args\n",
    "        pass\n",
    "\n",
    "    def execute(self, **kwargs):\n",
    "        self.validate_args(**kwargs)\n",
    "        return self.function(**kwargs)\n",
    "\n",
    "class ToolBank:\n",
    "    def __init__(self, db_path='tool_bank.db'):\n",
    "        self.db_path = db_path\n",
    "        self.db_connection = sqlite3.connect(db_path)\n",
    "        self.initialize_db()\n",
    "        self.tools = {}  # Cache tools in memory for quicker access\n",
    "\n",
    "    def initialize_db(self):\n",
    "        cursor = self.db_connection.cursor()\n",
    "        cursor.execute('''CREATE TABLE IF NOT EXISTS tools (\n",
    "            id INTEGER PRIMARY KEY,\n",
    "            name TEXT NOT NULL,\n",
    "            description TEXT NOT NULL,\n",
    "            args TEXT NOT NULL\n",
    "        )''')\n",
    "        self.db_connection.commit()\n",
    "\n",
    "    def add_tool(self, tool: Tool):\n",
    "        cursor = self.db_connection.cursor()\n",
    "        cursor.execute('INSERT INTO tools (name, description, args) VALUES (?, ?, ?)', \n",
    "                       (tool.name, tool.description, json.dumps(tool.args)))\n",
    "        self.db_connection.commit()\n",
    "        self.tools[tool.name] = tool  # Cache the tool\n",
    "\n",
    "    def search_tools(self, description: str) -> Tool:\n",
    "        # This method now returns a Tool instance for better encapsulation\n",
    "        cursor = self.db_connection.cursor()\n",
    "        cursor.execute('SELECT name, description, args FROM tools')\n",
    "        tools = cursor.fetchall()\n",
    "        tool_descriptions = [tool[1] for tool in tools]\n",
    "        vectorizer = TfidfVectorizer().fit(tool_descriptions)\n",
    "        query_vec = vectorizer.transform([description])\n",
    "        similarity = cosine_similarity(query_vec, vectorizer.transform(tool_descriptions))\n",
    "        most_similar_index = similarity.argmax()\n",
    "        tool_data = tools[most_similar_index]\n",
    "        tool_args = json.loads(tool_data[2])\n",
    "        # Assuming tool functions are globally accessible for simplicity; could use a more secure/flexible approach\n",
    "        return self.tools[tool_data[0]]\n",
    "\n",
    "    def execute_tool(self, tool_name: str, **kwargs):\n",
    "        tool = self.tools.get(tool_name)\n",
    "        if tool:\n",
    "            return tool.execute(**kwargs)\n",
    "        else:\n",
    "            raise KeyError(\"Tool not found.\")\n",
    "            \n",
    "    async def execute_tool_async(self, tool_name: str, **kwargs):\n",
    "        tool = self.tools.get(tool_name)\n",
    "        if tool:\n",
    "            # Assume tool.execute is an async function\n",
    "            return await tool.execute(**kwargs)\n",
    "        else:\n",
    "            raise KeyError(\"Tool not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "089b1137-c107-444b-a038-c696d4c65cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ToolBank:\n",
    "    def __init__(self, json_path='tool_bank.json'):\n",
    "        self.json_path = json_path\n",
    "        self.tools = {}  # Cache tools in memory for quicker access\n",
    "        self.load_tools()\n",
    "\n",
    "    def load_tools(self):\n",
    "        with open(self.json_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            for tool_data in data[\"tools\"]:\n",
    "                exec(tool_data[\"code\"], globals())\n",
    "                self.tools[tool_data[\"name\"]] = {\n",
    "                    \"function\": globals()[tool_data[\"name\"]],\n",
    "                    \"args\": tool_data[\"args\"],\n",
    "                    \"description\": tool_data[\"description\"]\n",
    "                }\n",
    "\n",
    "    def add_tool(self, name: str, description: str, args: dict, code: str):\n",
    "        tool_data = {\n",
    "            \"name\": name,\n",
    "            \"description\": description,\n",
    "            \"args\": args,\n",
    "            \"code\": code\n",
    "        }\n",
    "        # Update the tools dictionary\n",
    "        exec(code, globals())\n",
    "        self.tools[name] = {\n",
    "            \"function\": globals()[name],\n",
    "            \"args\": args,\n",
    "            \"description\": description\n",
    "        }\n",
    "        # Save to JSON\n",
    "        self.save_to_json(tool_data)\n",
    "\n",
    "    def save_to_json(self, tool_data):\n",
    "        with open(self.json_path, 'r+') as file:\n",
    "            data = json.load(file)\n",
    "            data[\"tools\"].append(tool_data)\n",
    "            file.seek(0)\n",
    "            json.dump(data, file, indent=4)\n",
    "\n",
    "    def execute_tool(self, tool_name: str, **kwargs):\n",
    "        tool = self.tools.get(tool_name)\n",
    "        if tool:\n",
    "            return tool[\"function\"](**kwargs)\n",
    "        else:\n",
    "            raise KeyError(\"Tool not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98ea9aff-099a-4c18-93a4-6105bd2b909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_bank = ToolBank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4709ee5-bed5-49c4-9fda-50928bb1ed5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'multiply': {'function': <function __main__.multiply(a, b)>,\n",
       "  'args': {'a': {'title': 'A', 'type': 'integer'},\n",
       "   'b': {'title': 'B', 'type': 'integer'}},\n",
       "  'description': 'Multiply two numbers.'},\n",
       " 'concat': {'function': <function __main__.concat(a, b)>,\n",
       "  'args': {'a': {'title': 'A', 'type': 'string'},\n",
       "   'b': {'title': 'B', 'type': 'string'}},\n",
       "  'description': 'Concatenate two strings.'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_bank.tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d882de64-3021-43f8-8b02-53117c78984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install torch\n",
    "# !pip install PyYAML\n",
    "\n",
    "\n",
    "# from langchain.tools import tool\n",
    "\n",
    "# @tool\n",
    "# def multiply(a: int, b: int) -> int:\n",
    "#     \"\"\"Multiply two numbers.\"\"\"\n",
    "#     return a * b\n",
    "\n",
    "# @tool\n",
    "# def concat(a: str, b: str) -> str:\n",
    "#     \"\"\"Concatenate two strings.\"\"\"\n",
    "#     return a + b\n",
    "\n",
    "# print(\"Tool name: \", multiply.name)\n",
    "# print(\"Tool description: \", multiply.description)\n",
    "# print(\"Tool argument schema: \", multiply.args)\n",
    "\n",
    "# multiply\n",
    "# multiply(a: int, b: int) -> int - Multiply two numbers.\n",
    "# {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n",
    "\n",
    "\n",
    "# # Example tool descriptions\n",
    "# example_tools = [\n",
    "#     {'name': multiply.name, 'description': multiply.description, \n",
    "#      'args': multiply.args, 'function': multiply},\n",
    "#     {'name': concat.name, 'description': concat.description, \n",
    "#      'args': concat.args, 'function': concat}\n",
    "    \n",
    "# ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "''' tool_bank.yaml\n",
    "tools:\n",
    "  - name: multiply\n",
    "    description: Multiply two numbers.\n",
    "    args:\n",
    "      a:\n",
    "        title: A\n",
    "        type: integer\n",
    "      b:\n",
    "        title: B\n",
    "        type: integer\n",
    "    code: |\n",
    "      def multiply(a, b): return a * b\n",
    "  \n",
    "  - name: concat\n",
    "    description: Concatenate two strings.\n",
    "    args:\n",
    "      a:\n",
    "        title: A\n",
    "        type: string\n",
    "      b:\n",
    "        title: B\n",
    "        type: string\n",
    "    code: |\n",
    "      def concat(a, b): return a + b\n",
    "'''\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "class ToolBank:\n",
    "    def __init__(self, yaml_path='tool_bank.yaml', model_name='sentence-transformers/all-MiniLM-L6-v2'):\n",
    "        self.yaml_path = yaml_path\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.tools = {}  \n",
    "        self.load_tools()\n",
    "        self.embeddings = self.generate_embeddings()\n",
    "\n",
    "    def load_tools(self):\n",
    "        with open(self.yaml_path, 'r') as file:\n",
    "            data = yaml.safe_load(file)\n",
    "            for tool_data in data[\"tools\"]:\n",
    "                # Assuming security is managed and the code comes from a trusted source\n",
    "                exec(tool_data[\"code\"], globals())\n",
    "                self.tools[tool_data[\"name\"]] = {\n",
    "                    \"function\": globals()[tool_data[\"name\"]],\n",
    "                    \"args\": tool_data[\"args\"],\n",
    "                    \"description\": tool_data[\"description\"]\n",
    "                }\n",
    "\n",
    "    def add_tool(self, name: str, description: str, args: dict, code: str):\n",
    "        tool_data = {\n",
    "            \"name\": name,\n",
    "            \"description\": description,\n",
    "            \"args\": args,\n",
    "            \"code\": code\n",
    "        }\n",
    "        # Update the tools dictionary\n",
    "        exec(code, globals())\n",
    "        self.tools[name] = {\n",
    "            \"function\": globals()[name],\n",
    "            \"args\": args,\n",
    "            \"description\": description\n",
    "        }\n",
    "        # Save to YAML\n",
    "        self.save_to_yaml(tool_data)\n",
    "\n",
    "    def save_to_yaml(self, tool_data):\n",
    "        with open(self.yaml_path, 'r') as file:\n",
    "            data = yaml.safe_load(file) or {\"tools\": []}\n",
    "        data[\"tools\"].append(tool_data)\n",
    "        with open(self.yaml_path, 'w') as file:\n",
    "            yaml.safe_dump(data, file)\n",
    "\n",
    "    def execute_tool(self, tool_name: str, **kwargs):\n",
    "        tool = self.tools.get(tool_name)\n",
    "        if tool:\n",
    "            return tool[\"function\"](**kwargs)\n",
    "        else:\n",
    "            raise KeyError(\"Tool not found.\")\n",
    "\n",
    "\n",
    "    def generate_embeddings(self):\n",
    "        embeddings = []\n",
    "        for description in [tool[\"description\"] for tool in self.tools.values()]:\n",
    "            inputs = self.tokenizer(description, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "            embeddings.append(outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy())\n",
    "        return np.array(embeddings)\n",
    "\n",
    "    def search_tools(self, query):\n",
    "        inputs = self.tokenizer(query, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        query_embedding = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "        \n",
    "        similarity_scores = cosine_similarity([query_embedding], self.embeddings)[0]\n",
    "        most_similar_indices = similarity_scores.argsort()[::-1]\n",
    "        # Return the names of the top matching tools\n",
    "        return [list(self.tools.keys())[i] for i in most_similar_indices[0:1]]  \n",
    "\n",
    "tb = ToolBank()\n",
    "\n",
    "tb.search_tools('I need a tool that concat two strings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b789ab52-5005-484f-86cb-25cb04f54132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
