{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90e0378a-4339-43c0-9675-b18e1960ffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install open-interpreter crewai gradio langchain langchain-community\n",
    "# !pip install --upgrade open-interpreter\n",
    "# !pip install SpeechRecognition\n",
    "# !pip install pyaudio\n",
    "# !pip install sounddevice wavio SpeechRecognition gTTS pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5ce90cb-409a-42a8-9657-870861c3b96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.2, Python 3.11.0)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from interpreter import interpreter\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# For audio\n",
    "import speech_recognition as sr\n",
    "import sounddevice as sd\n",
    "import wavio\n",
    "import numpy as np\n",
    "from gtts import gTTS\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79c01d89-91c4-4488-a009-81ae0a4586a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Configuration and Tools\n",
    "# llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
    "# interpreter.auto_run = True\n",
    "# interpreter.llm.model = \"openai/gpt-4-turbo-preview\"\n",
    "\n",
    "# class CLITool:\n",
    "#     @tool(\"Executor\")\n",
    "#     def execute_cli_command(command: str):\n",
    "#         \"\"\"Create and Execute code using Open Interpreter.\"\"\"\n",
    "#         result = interpreter.chat(command)\n",
    "#         return result\n",
    "\n",
    "# # 2. Creating an Agent for CLI tasks\n",
    "# cli_agent = Agent(\n",
    "#     role='Software Engineer',\n",
    "#     goal='Always use Executor Tool. Ability to perform CLI operations, write programs and execute using Exector Tool',\n",
    "#     backstory='Expert in command line operations, creating and executing code.',\n",
    "#     tools=[CLITool.execute_cli_command],\n",
    "#     verbose=True,\n",
    "#     llm=llm \n",
    "# )\n",
    "\n",
    "# # 3. Defining a Task for CLI operations\n",
    "# cli_task = Task(\n",
    "#     description='Open my Mozilla web browser and navigate to wikipedia.',\n",
    "#     agent=cli_agent,\n",
    "#     tools=[CLITool.execute_cli_command]\n",
    "# )\n",
    "\n",
    "# # 4. Creating a Crew with CLI focus\n",
    "# cli_crew = Crew(\n",
    "#     agents=[cli_agent],\n",
    "#     tasks=[cli_task],\n",
    "#     process=Process.sequential,\n",
    "#     manager_llm=llm\n",
    "# )\n",
    "\n",
    "# # 5. Run the Crew\n",
    "# result = cli_crew.kickoff()\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e73bb62-c09d-4405-a00c-b5cbbdaac340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Could not understand audio\n",
      "Listening...\n",
      "Recognized: hello\n",
      "Listening...\n",
      "Could not understand audio\n",
      "Listening...\n",
      "Recognized: start Task\n",
      "Start capturing tasks...\n",
      "Listening...\n",
      "Recognized: tell me what files are on my desktop\n",
      "Listening...\n",
      "Could not understand audio\n",
      "Listening...\n",
      "Recognized: stop tasks\n",
      "End capturing commands. Command: tell me what files are on my desktop\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: Executor\n",
      "Action Input: ls ~/Desktop\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">We were unable to determine the context window of this model.</span> Defaulting to 3000.                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mWe were unable to determine the context window of this model.\u001b[0m Defaulting to 3000.                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">If your model can handle more, run <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">interpreter.llm.context_window = {token limit}</span>.                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "If your model can handle more, run \u001b[1;36;40minterpreter.llm.context_window = {token limit}\u001b[0m.                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Also please set <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">interpreter.llm.max_tokens = {max tokens per response}</span>.                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Also please set \u001b[1;36;40minterpreter.llm.max_tokens = {max tokens per response}\u001b[0m.                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Continuing...                                                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Continuing...                                                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/ty/miniconda/envs/first/lib/python3.11/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/ty/miniconda/envs/first/lib/python3.11/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[{'role': 'user', 'type': 'message', 'content': 'ls ~/Desktop'}, {'role': 'assistant', 'type': 'code', 'format': 'bash', 'content': '\\nls ~/Desktop\\n'}, {'role': 'computer', 'type': 'console', 'format': 'output', 'content': '\\n\\ncrewai\\nopenai_key\\nUntitled.ipynb\\nvideos\\n\\n'}, {'role': 'assistant', 'type': 'message', 'content': \"The output from thels command you see lists the contents of your Desktop directory. It shows you have four items:\\n\\n-crewai`: This could be a directory or a file related to the work you mentioned earlier.\\n-openai_key`: Likely a file containing an API key for OpenAI services.\\n-Untitled.ipynb`: A Jupyter notebook file, often used for Python programming and data analysis.\\n-videos`: This might be a directory containing video files.\\n\\nIf there's a specific task or operation you want to perform on any of these items, or if there's something else you have in mind, please let me know how I can assist you further!\"}]\u001b[0m\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
      "Final Answer: The files on your desktop are:\n",
      "- crewai\n",
      "- openai_key\n",
      "- Untitled.ipynb\n",
      "- videos\n",
      "\n",
      "These could be either files or directories. If you need further operations or details on these items, please specify.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The files on your desktop are:\n",
      "- crewai\n",
      "- openai_key\n",
      "- Untitled.ipynb\n",
      "- videos\n",
      "\n",
      "These could be either files or directories. If you need further operations or details on these items, please specify.\n",
      "Listening...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 106\u001b[0m\n\u001b[1;32m    103\u001b[0m                 command_buffer\u001b[38;5;241m.\u001b[39mappend(speech_text)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# if __name__ == \"__main__\":\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m \u001b[43mcontinuous_listen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 65\u001b[0m, in \u001b[0;36mcontinuous_listen\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m listening_for_command \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     audio_filename \u001b[38;5;241m=\u001b[39m \u001b[43mrecord_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Record for short durations\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     speech_text \u001b[38;5;241m=\u001b[39m recognize_speech_from_file(recognizer, audio_filename)\n\u001b[1;32m     67\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(audio_filename)  \u001b[38;5;66;03m# Clean up the temporary file\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 28\u001b[0m, in \u001b[0;36mrecord_audio\u001b[0;34m(duration, fs, filename)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mListening...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m recording \u001b[38;5;241m=\u001b[39m sd\u001b[38;5;241m.\u001b[39mrec(\u001b[38;5;28mint\u001b[39m(duration \u001b[38;5;241m*\u001b[39m fs), samplerate\u001b[38;5;241m=\u001b[39mfs, channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint16)\n\u001b[0;32m---> 28\u001b[0m \u001b[43msd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m wavio\u001b[38;5;241m.\u001b[39mwrite(filename, recording, fs, sampwidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m filename\n",
      "File \u001b[0;32m~/miniconda/envs/first/lib/python3.11/site-packages/sounddevice.py:395\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(ignore_errors)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for `play()`/`rec()`/`playrec()` to be finished.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03mPlayback/recording can be stopped with a `KeyboardInterrupt`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m \n\u001b[1;32m    393\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _last_callback:\n\u001b[0;32m--> 395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_last_callback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/first/lib/python3.11/site-packages/sounddevice.py:2601\u001b[0m, in \u001b[0;36m_CallbackContext.wait\u001b[0;34m(self, ignore_errors)\u001b[0m\n\u001b[1;32m   2595\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for finished_callback.\u001b[39;00m\n\u001b[1;32m   2596\u001b[0m \n\u001b[1;32m   2597\u001b[0m \u001b[38;5;124;03mCan be interrupted with a KeyboardInterrupt.\u001b[39;00m\n\u001b[1;32m   2598\u001b[0m \n\u001b[1;32m   2599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2600\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2601\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2602\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2603\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mclose(ignore_errors)\n",
      "File \u001b[0;32m~/miniconda/envs/first/lib/python3.11/threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    620\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 622\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda/envs/first/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from openai_key import key\n",
    "os.environ[\"OPENAI_API_KEY\"] = key\n",
    "\n",
    "# Configuration and Tools\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
    "interpreter.auto_run = True\n",
    "interpreter.llm.model = \"openai/gpt-4-turbo-preview\"\n",
    "\n",
    "class CLITool:\n",
    "    @tool(\"Executor\")\n",
    "    def execute_cli_command(command: str):\n",
    "        \"\"\"Create and Execute code using Open Interpreter.\"\"\"\n",
    "        result = interpreter.chat(command)\n",
    "        return result\n",
    "\n",
    "cli_agent = Agent(\n",
    "    role='Software Engineer',\n",
    "    goal='Always use Executor Tool. Ability to perform CLI operations, write programs and execute using Executor Tool',\n",
    "    backstory='Expert in command line operations, creating and executing code.',\n",
    "    tools=[CLITool.execute_cli_command],\n",
    "    verbose=True,\n",
    "    llm=llm \n",
    ")\n",
    "\n",
    "# Function to record audio for a short duration and return the file path\n",
    "def record_audio(duration=5, fs=44100, filename=\"temp_recording.wav\"):\n",
    "    print(\"Listening...\")\n",
    "    recording = sd.rec(int(duration * fs), samplerate=fs, channels=2, dtype=np.int16)\n",
    "    sd.wait()\n",
    "    wavio.write(filename, recording, fs, sampwidth=2)\n",
    "    return filename\n",
    "\n",
    "# Function to recognize speech from an audio file using speech_recognition\n",
    "def recognize_speech_from_file(recognizer, audio_file):\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio_data)\n",
    "        print(f\"Recognized: {text}\")\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Could not understand audio\")\n",
    "        return None\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Could not request results; {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to speak text using gTTS and pygame\n",
    "def speak_text(text):\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    filename = 'temp_speech.mp3'\n",
    "    tts.save(filename)\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load(filename)\n",
    "    pygame.mixer.music.play()\n",
    "    while pygame.mixer.music.get_busy():\n",
    "        pygame.time.Clock().tick(10)\n",
    "    os.remove(filename)\n",
    "\n",
    "def continuous_listen():\n",
    "    recognizer = sr.Recognizer()\n",
    "    command_buffer = []\n",
    "    listening_for_command = False\n",
    "\n",
    "    while True:\n",
    "        audio_filename = record_audio(duration=5)  # Record for short durations\n",
    "        speech_text = recognize_speech_from_file(recognizer, audio_filename)\n",
    "        os.remove(audio_filename)  # Clean up the temporary file\n",
    "\n",
    "        if speech_text:\n",
    "            if \"start task\" in speech_text.lower():\n",
    "                listening_for_command = True\n",
    "                command_buffer = []\n",
    "                speak_text('Listening for tasks.')\n",
    "                print(\"Start capturing tasks...\")\n",
    "                continue\n",
    "\n",
    "            if \"stop task\" in speech_text.lower() and listening_for_command:\n",
    "                listening_for_command = False\n",
    "                command_text = \", \".join(command_buffer)\n",
    "                print(f\"End capturing commands. Command: {command_text}\")\n",
    "                speak_text(f\"Processing command: {command_text}\")\n",
    "                if command_text:\n",
    "                    cli_task = Task(\n",
    "                        description=command_text,\n",
    "                        agent=cli_agent,\n",
    "                        tools=[CLITool.execute_cli_command]\n",
    "                    )\n",
    "                \n",
    "                    cli_crew = Crew(\n",
    "                        agents=[cli_agent],\n",
    "                        tasks=[cli_task],\n",
    "                        process=Process.sequential,\n",
    "                        manager_llm=llm\n",
    "                    )\n",
    "                \n",
    "                    result = cli_crew.kickoff()\n",
    "                    print(result)\n",
    "                    speak_text(result)\n",
    "                command_buffer = []\n",
    "                continue\n",
    "\n",
    "            if listening_for_command:\n",
    "                command_buffer.append(speech_text)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "continuous_listen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39423ef4-3cc3-4f0f-beca-9227619a008a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
