{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3951b3-9486-439b-946f-c36cbbb31df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib qt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from IPython.display import clear_output\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "class DFTModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(DFTModel, self).__init__()\n",
    "        self.channel_dft = layers.Lambda(lambda x: tf.signal.fft2d(x))\n",
    "        self.log_scale = layers.Lambda(lambda x: tf.math.log(tf.abs(x) + 1e-9))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.cast(inputs, tf.complex64)\n",
    "        x = tf.transpose(x, [0,3,1,2]) # move channel axis to the front\n",
    "        x = self.channel_dft(x)\n",
    "        # Extract the real and imaginary parts\n",
    "        xreal = tf.math.real(x)\n",
    "        ximag = tf.math.imag(x)\n",
    "        \n",
    "        # Calculate the absolute value\n",
    "        x = tf.math.sqrt(xreal**2+ximag**2)\n",
    "        x = self.log_scale(x)\n",
    "        x = tf.transpose(x, [0,2,3,1]) # move channel axis back\n",
    "        x = (x - tf.reduce_min(x)) / (tf.reduce_max(x) - tf.reduce_min(x))\n",
    "        x *= 255\n",
    "        x = tf.cast(x, tf.uint8)\n",
    "        return x\n",
    "    \n",
    "model = DFTModel()\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set the width and height of the video\n",
    "cap.set(3, 640)  # width\n",
    "cap.set(4, 480)  # height\n",
    "n = 0\n",
    "mean = None\n",
    "M2 = None\n",
    "fig=plt.figure()\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    clear_output(wait=True)\n",
    "    dft = model(frame[np.newaxis,...]).numpy()[0]\n",
    "    \n",
    "    # Update mean and standard deviation using Welford's method\n",
    "    n += .1\n",
    "    if mean is None:\n",
    "        mean = dft\n",
    "        M2 = np.ones(mean.shape)\n",
    "    else:\n",
    "        delta = dft - mean\n",
    "        mean += (delta / n).astype(np.uint8)\n",
    "        M2 += delta * (dft - mean)\n",
    "\n",
    "    # Calculate standard deviation\n",
    "    if n < 2:\n",
    "        std = None\n",
    "    else:\n",
    "        std = np.sqrt(M2 / (n - 1))    \n",
    "    \n",
    "    final = np.concatenate([frame, dft, mean],axis=1)\n",
    "    plt.imshow(cv2.cvtColor(final, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8f6d7c-2ea0-430f-ab2d-87b3896e8114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to initialize the model if you didn't do inference above.\n",
    "# model = DFTModel()\n",
    "# x = np.zeros((1,480,640,3))\n",
    "# y = model(x)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.target_spec.supported_ops = [\n",
    "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
    "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
    "]\n",
    "tflite_model = converter.convert()\n",
    "open(\"dft_model.tflite\", \"wb\").write(tflite_model)\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=\"dft_model.tflite\")\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# help(interpreter)\n",
    "interpreter.get_input_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb664a6-cb17-46f1-a232-3de2bcbfbe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_tensor(interpreter, i):\n",
    "  \"\"\"Gets a model's ith output tensor.\n",
    "\n",
    "  Args:\n",
    "    interpreter: The ``tf.lite.Interpreter`` holding the model.\n",
    "    i (int): The index position of an output tensor.\n",
    "  Returns:\n",
    "    The output tensor at the specified position.\n",
    "  \"\"\"\n",
    "  return interpreter.tensor(interpreter.get_output_details()[i]['index'])()\n",
    "\n",
    "\n",
    "def input_details(interpreter, key):\n",
    "  \"\"\"Gets a model's input details by specified key.\n",
    "\n",
    "  Args:\n",
    "    interpreter: The ``tf.lite.Interpreter`` holding the model.\n",
    "    key (int): The index position of an input tensor.\n",
    "  Returns:\n",
    "    The input details.\n",
    "  \"\"\"\n",
    "  return interpreter.get_input_details()[0][key]\n",
    "\n",
    "\n",
    "def input_size(interpreter):\n",
    "  \"\"\"Gets a model's input size as (width, height) tuple.\n",
    "\n",
    "  Args:\n",
    "    interpreter: The ``tf.lite.Interpreter`` holding the model.\n",
    "  Returns:\n",
    "    The input tensor size as (width, height) tuple.\n",
    "  \"\"\"\n",
    "  _, height, width, _ = input_details(interpreter, 'shape')\n",
    "  return width, height\n",
    "\n",
    "\n",
    "def input_tensor(interpreter):\n",
    "  \"\"\"Gets a model's input tensor view as numpy array of shape (height, width, 3).\n",
    "\n",
    "  Args:\n",
    "    interpreter: The ``tf.lite.Interpreter`` holding the model.\n",
    "  Returns:\n",
    "    The input tensor view as :obj:`numpy.array` (height, width, 3).\n",
    "  \"\"\"\n",
    "  tensor_index = input_details(interpreter, 'index')\n",
    "  return interpreter.tensor(tensor_index)()[0]\n",
    "\n",
    "\n",
    "def set_input(interpreter, data):\n",
    "  \"\"\"Copies data to a model's input tensor.\n",
    "\n",
    "  Args:\n",
    "    interpreter: The ``tf.lite.Interpreter`` to update.\n",
    "    data: The input tensor.\n",
    "  \"\"\"\n",
    "  input_tensor(interpreter)[:, :] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f957321-a93e-4b7a-ba95-525444e318f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_input(interpreter, frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9d940b-c081-4c31-916f-af2f28db9179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpreter.invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772d2eb6-0a05-4b2f-b7aa-12c1f8238b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_details = interpreter.get_output_details()[0]\n",
    "# output_data = interpreter.tensor(output_details['index'])().copy()\n",
    "# output_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6ebe39-3d7f-4eff-995c-25c203ec5c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Set the width and height of the video\n",
    "cap.set(3, 640)  # width\n",
    "cap.set(4, 480)  # height\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    clear_output(wait=True)\n",
    "    x = tf.convert_to_tensor(frame)\n",
    "    x = x[tf.newaxis,...]\n",
    "    set_input(interpreter, x)\n",
    "    interpreter.invoke()\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "    output_data = interpreter.tensor(output_details['index'])()[0].copy()\n",
    "    final = np.concatenate([frame, output_data],axis=1)\n",
    "    plt.imshow(cv2.cvtColor(final, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fa98dd-b74a-4b5c-b949-6212f7fe8021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd73fb79-60ab-46e9-b616-1bb0866ecc8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
